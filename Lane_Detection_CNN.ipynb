{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNrJFRs1yx/OopIOcg57AoX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mishra-0709/Anveshan-Smart-Vehicle-BlackGriffin/blob/main/Lane_Detection_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "Ld5VKHCxkoSR",
        "outputId": "3dde9df5-02a1-444e-a755-a89fb54e4138"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/moviepy/video/io/sliders.py:61: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "  if event.key is 'enter':\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "MoviePy error: the file input_video.mp4 could not be found!\nPlease check that you entered the correct path.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-9821dda85b6a>\u001b[0m in \u001b[0;36m<cell line: 161>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0minput_video_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"input_video.mp4\"\u001b[0m  \u001b[0;31m# Path to the input video\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0moutput_video_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"output_video.mp4\"\u001b[0m  \u001b[0;31m# Path to save the processed video\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m \u001b[0mprocess_video\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_video_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_video_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-1-9821dda85b6a>\u001b[0m in \u001b[0;36mprocess_video\u001b[0;34m(input_video_path, output_video_path)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0moutput_video_path\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mLocation\u001b[0m \u001b[0mto\u001b[0m \u001b[0msave\u001b[0m \u001b[0mthe\u001b[0m \u001b[0moutput\u001b[0m \u001b[0mvideo\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mdetected\u001b[0m \u001b[0mlane\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \"\"\"\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0minput_video\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVideoFileClip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_video_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mprocessed_video\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_video\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfl_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_frame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mprocessed_video\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_videofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_video_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/moviepy/video/io/VideoFileClip.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, has_mask, audio, audio_buffersize, target_resolution, resize_algorithm, audio_fps, audio_nbytes, verbose, fps_source)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;31m# Make a reader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mpix_fmt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"rgba\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhas_mask\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"rgb24\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         self.reader = FFMPEG_VideoReader(filename, pix_fmt=pix_fmt,\n\u001b[0m\u001b[1;32m     89\u001b[0m                                          \u001b[0mtarget_resolution\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_resolution\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                                          \u001b[0mresize_algo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresize_algorithm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/moviepy/video/io/ffmpeg_reader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, print_infos, bufsize, pix_fmt, check_duration, target_resolution, resize_algo, fps_source)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         infos = ffmpeg_parse_infos(filename, print_infos, check_duration,\n\u001b[0m\u001b[1;32m     36\u001b[0m                                    fps_source)\n\u001b[1;32m     37\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'video_fps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/moviepy/video/io/ffmpeg_reader.py\u001b[0m in \u001b[0;36mffmpeg_parse_infos\u001b[0;34m(filename, print_infos, check_duration, fps_source)\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m\"No such file or directory\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m         raise IOError((\"MoviePy error: the file %s could not be found!\\n\"\n\u001b[0m\u001b[1;32m    271\u001b[0m                       \u001b[0;34m\"Please check that you entered the correct \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m                       \"path.\")%filename)\n",
            "\u001b[0;31mOSError\u001b[0m: MoviePy error: the file input_video.mp4 could not be found!\nPlease check that you entered the correct path."
          ]
        }
      ],
      "source": [
        "# Install OpenCV if not already installed\n",
        "!pip install -q opencv-python moviepy\n",
        "\n",
        "# Import necessary libraries\n",
        "import cv2\n",
        "import numpy as np\n",
        "from moviepy.editor import VideoFileClip\n",
        "\n",
        "# Function to process video frames for lane detection\n",
        "def process_video(input_video_path, output_video_path):\n",
        "    \"\"\"\n",
        "    Processes an input video to detect lane lines and saves the output video.\n",
        "    :param input_video_path: Location of the input video file\n",
        "    :param output_video_path: Location to save the output video file with detected lane lines\n",
        "    \"\"\"\n",
        "    input_video = VideoFileClip(input_video_path)\n",
        "    processed_video = input_video.fl_image(process_frame)\n",
        "    processed_video.write_videofile(output_video_path, audio=False)\n",
        "\n",
        "# Frame processing function for lane detection\n",
        "def process_frame(image):\n",
        "    \"\"\"\n",
        "    Detect lane lines in an individual frame.\n",
        "    :param image: A single frame (image) from the video\n",
        "    :return: The frame with detected lane lines drawn on it\n",
        "    \"\"\"\n",
        "    # Step 1: Grayscale conversion\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Step 2: Apply Gaussian Blur for noise reduction\n",
        "    kernel_size = 5\n",
        "    blur_gray = cv2.GaussianBlur(gray, (kernel_size, kernel_size), 0)\n",
        "\n",
        "    # Step 3: Canny Edge Detection\n",
        "    low_threshold = 50\n",
        "    high_threshold = 150\n",
        "    edges = cv2.Canny(blur_gray, low_threshold, high_threshold)\n",
        "\n",
        "    # Step 4: Region of Interest Selection\n",
        "    region = region_of_interest(edges)\n",
        "\n",
        "    # Step 5: Hough Transform to Detect Lane Lines\n",
        "    lines = hough_lines(region)\n",
        "\n",
        "    # Step 6: Draw Lane Lines on the Original Image\n",
        "    result = draw_lane_lines(image, lane_lines(image, lines))\n",
        "    return result\n",
        "\n",
        "# Define the Region of Interest (ROI) Mask\n",
        "def region_of_interest(image):\n",
        "    \"\"\"\n",
        "    Applies an image mask to focus on the area where lane lines are expected.\n",
        "    :param image: Edge-detected image\n",
        "    :return: Masked image with only region of interest\n",
        "    \"\"\"\n",
        "    mask = np.zeros_like(image)\n",
        "    ignore_mask_color = 255\n",
        "    rows, cols = image.shape[:2]\n",
        "    bottom_left = [cols * 0.1, rows * 0.95]\n",
        "    top_left = [cols * 0.4, rows * 0.6]\n",
        "    bottom_right = [cols * 0.9, rows * 0.95]\n",
        "    top_right = [cols * 0.6, rows * 0.6]\n",
        "    vertices = np.array([[bottom_left, top_left, top_right, bottom_right]], dtype=np.int32)\n",
        "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
        "    masked_image = cv2.bitwise_and(image, mask)\n",
        "    return masked_image\n",
        "\n",
        "# Hough Transform for Line Detection\n",
        "def hough_lines(image):\n",
        "    \"\"\"\n",
        "    Applies Hough Transform to detect lines in the masked edge-detected image.\n",
        "    :param image: Masked edge-detected image\n",
        "    :return: Lines detected using Hough Transform\n",
        "    \"\"\"\n",
        "    rho = 1            # distance resolution in pixels\n",
        "    theta = np.pi / 180  # angular resolution in radians\n",
        "    threshold = 20      # minimum number of votes\n",
        "    min_line_length = 20 # minimum number of pixels to qualify as a line\n",
        "    max_line_gap = 300   # maximum gap in pixels between line segments to link them\n",
        "    lines = cv2.HoughLinesP(image, rho, theta, threshold, np.array([]),\n",
        "                            minLineLength=min_line_length, maxLineGap=max_line_gap)\n",
        "    return lines\n",
        "\n",
        "# Functions to draw lane lines and calculate slope\n",
        "def average_slope_intercept(lines):\n",
        "    \"\"\"\n",
        "    Calculates the average slope and intercept for the left and right lanes.\n",
        "    :param lines: Array of lines detected from Hough Transform\n",
        "    :return: Left and right lane lines\n",
        "    \"\"\"\n",
        "    left_lines = []\n",
        "    right_lines = []\n",
        "    left_weights = []\n",
        "    right_weights = []\n",
        "\n",
        "    for line in lines:\n",
        "        for x1, y1, x2, y2 in line:\n",
        "            slope = (y2 - y1) / (x2 - x1) if x1 != x2 else 0\n",
        "            intercept = y1 - slope * x1\n",
        "            length = np.sqrt((y2 - y1)**2 + (x2 - x1)**2)\n",
        "\n",
        "            if slope < 0:  # left lane\n",
        "                left_lines.append((slope, intercept))\n",
        "                left_weights.append((length))\n",
        "            else:  # right lane\n",
        "                right_lines.append((slope, intercept))\n",
        "                right_weights.append((length))\n",
        "\n",
        "    left_lane = np.dot(left_weights, left_lines) / np.sum(left_weights) if len(left_weights) > 0 else None\n",
        "    right_lane = np.dot(right_weights, right_lines) / np.sum(right_weights) if len(right_weights) > 0 else None\n",
        "\n",
        "    return left_lane, right_lane\n",
        "\n",
        "def pixel_points(y1, y2, line):\n",
        "    \"\"\"\n",
        "    Converts a line's slope and intercept to pixel points.\n",
        "    :param y1, y2: The start and end y-coordinates of the line\n",
        "    :param line: Slope and intercept of the line\n",
        "    :return: (x1, y1), (x2, y2) points of the line\n",
        "    \"\"\"\n",
        "    if line is None:\n",
        "        return None\n",
        "    slope, intercept = line\n",
        "    x1 = int((y1 - intercept) / slope)\n",
        "    x2 = int((y2 - intercept) / slope)\n",
        "    return (x1, y1), (x2, y2)\n",
        "\n",
        "def lane_lines(image, lines):\n",
        "    \"\"\"\n",
        "    Compute the coordinates for lane lines.\n",
        "    :param image: The input frame\n",
        "    :param lines: Lines detected from Hough Transform\n",
        "    :return: Pixel points for the left and right lane lines\n",
        "    \"\"\"\n",
        "    left_lane, right_lane = average_slope_intercept(lines)\n",
        "    y1 = image.shape[0]\n",
        "    y2 = int(y1 * 0.6)\n",
        "    left_line = pixel_points(y1, y2, left_lane)\n",
        "    right_line = pixel_points(y1, y2, right_lane)\n",
        "    return left_line, right_line\n",
        "\n",
        "# Draw lane lines on the image\n",
        "def draw_lane_lines(image, lines, color=[255, 0, 0], thickness=10):\n",
        "    \"\"\"\n",
        "    Draw the computed lane lines onto the frame.\n",
        "    :param image: Input frame\n",
        "    :param lines: Computed left and right lane lines\n",
        "    :param color: Color of the lane lines\n",
        "    :param thickness: Thickness of the lane lines\n",
        "    :return: Frame with lane lines drawn\n",
        "    \"\"\"\n",
        "    line_image = np.zeros_like(image)\n",
        "    for line in lines:\n",
        "        if line is not None:\n",
        "            cv2.line(line_image, *line, color, thickness)\n",
        "    return cv2.addWeighted(image, 1.0, line_image, 1.0, 0.0)\n",
        "\n",
        "# Run lane detection on an example video\n",
        "input_video_path = \"input_video.mp4\"  # Path to the input video\n",
        "output_video_path = \"output_video.mp4\"  # Path to save the processed video\n",
        "process_video(input_video_path, output_video_path)\n"
      ]
    }
  ]
}