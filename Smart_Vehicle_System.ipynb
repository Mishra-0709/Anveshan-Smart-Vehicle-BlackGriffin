{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mishra-0709/Anveshan-Smart-Vehicle-BlackGriffin-/blob/main/Smart_Vehicle_System.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Collection"
      ],
      "metadata": {
        "id": "MgFNF75Bpa2c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bAgc7Mrjm214",
        "outputId": "81d8cb95-cea7-427a-c0ae-91437c6d05f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Target  AccMeanX  AccMeanY  AccMeanZ   AccCovX   AccCovY   AccCovZ  \\\n",
            "0       1  0.285339 -0.138611 -0.957764  0.022150  0.003975  0.001926   \n",
            "1       1  0.313477 -0.161670 -0.956250  0.020571  0.005640  0.001456   \n",
            "2       1  0.325195 -0.158325 -0.950155  0.017281  0.004579  0.001388   \n",
            "3       1  0.336565 -0.172468 -0.937640  0.015305  0.005216  0.002253   \n",
            "4       1  0.337860 -0.164185 -0.941681  0.013132  0.005020  0.002062   \n",
            "\n",
            "   AccSkewX  AccSkewY  AccSkewZ  ...  GyroMaxZ  GyroVarX  GyroVarY  GyroVarZ  \\\n",
            "0  0.867594 -1.305868 -0.507254  ...  0.832061  0.761120  0.184372  0.262859   \n",
            "1  0.002474 -0.395088 -0.677572  ...  0.832061  3.061080  0.585991  0.270340   \n",
            "2 -0.354212 -0.603657 -0.984635  ...  0.832061  3.137076  0.552431  0.905518   \n",
            "3 -0.655653 -0.152454 -0.040530  ...  0.832061  2.809524  3.963056  0.893127   \n",
            "4 -0.718488 -0.446061  0.250539  ...  0.832061  2.667567  3.414394  0.799787   \n",
            "\n",
            "   GyroMedianX  GyroMedianY  GyroMedianZ  GyroStdX  GyroStdY  GyroStdZ  \n",
            "0    -0.286260     4.251908     0.706107  0.872422  0.429385  0.512697  \n",
            "1     0.335878     3.969466     0.587786  1.749594  0.765501  0.519942  \n",
            "2    -0.286260     3.832061     0.240458  1.771179  0.743257  0.951587  \n",
            "3     0.335878     3.969466    -0.106870  1.676163  1.990743  0.945054  \n",
            "4    -0.286260     4.038168    -0.179389  1.633269  1.847808  0.894308  \n",
            "\n",
            "[5 rows x 61 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the dataset\n",
        "df_features = pd.read_csv('features_14.csv')\n",
        "\n",
        "# Display the first few rows of the dataframe\n",
        "print(df_features.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing"
      ],
      "metadata": {
        "id": "BnJ54V0apdzJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cleaning: Removing any rows with missing values\n",
        "df_features.dropna(inplace=True)\n",
        "\n",
        "# Normalization: Scaling the data\n",
        "scaler = StandardScaler()\n",
        "features = df_features.drop(columns=['Target'])\n",
        "scaled_features = scaler.fit_transform(features)\n",
        "\n",
        "# Add the target column back to the dataframe\n",
        "df_features_scaled = pd.DataFrame(scaled_features, columns=features.columns)\n",
        "df_features_scaled['Target'] = df_features['Target'].values\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X = df_features_scaled.drop(columns=['Target'])\n",
        "y = df_features_scaled['Target']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Data preprocessed successfully\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZsaTQfAkpfzE",
        "outputId": "d263b17b-7b2a-4dcb-a9fb-3e67afb8fa95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data preprocessed successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Training"
      ],
      "metadata": {
        "id": "m05iq8DCpiQ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "\n",
        "# Building the LSTM model for speed prediction\n",
        "speed_model = Sequential([\n",
        "    LSTM(100, input_shape=(X_train.shape[1], 1), return_sequences=True),\n",
        "    LSTM(50, return_sequences=False),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "speed_model.compile(optimizer='adam', loss='mse')\n",
        "speed_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "print(\"Speed Prediction Model trained successfully\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LxtL4iG-pkp7",
        "outputId": "3b278961-ce16-47a3-a137-8aed0f0bf396"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "22/22 [==============================] - 7s 101ms/step - loss: 3.8725 - val_loss: 1.1357\n",
            "Epoch 2/10\n",
            "22/22 [==============================] - 1s 59ms/step - loss: 1.1321 - val_loss: 0.9656\n",
            "Epoch 3/10\n",
            "22/22 [==============================] - 1s 60ms/step - loss: 1.0605 - val_loss: 0.9132\n",
            "Epoch 4/10\n",
            "22/22 [==============================] - 1s 61ms/step - loss: 0.9976 - val_loss: 0.8604\n",
            "Epoch 5/10\n",
            "22/22 [==============================] - 1s 61ms/step - loss: 0.9872 - val_loss: 0.8379\n",
            "Epoch 6/10\n",
            "22/22 [==============================] - 1s 60ms/step - loss: 0.9244 - val_loss: 0.7720\n",
            "Epoch 7/10\n",
            "22/22 [==============================] - 2s 69ms/step - loss: 0.8950 - val_loss: 0.7522\n",
            "Epoch 8/10\n",
            "22/22 [==============================] - 2s 93ms/step - loss: 0.8565 - val_loss: 0.7463\n",
            "Epoch 9/10\n",
            "22/22 [==============================] - 2s 74ms/step - loss: 0.8573 - val_loss: 0.8070\n",
            "Epoch 10/10\n",
            "22/22 [==============================] - 1s 60ms/step - loss: 0.8043 - val_loss: 0.6933\n",
            "Speed Prediction Model trained successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Collision Risk Assessment Model"
      ],
      "metadata": {
        "id": "t6s4uTE2pz-U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Building the Random Forest model for collision risk assessment\n",
        "collision_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "collision_model.fit(X_train, y_train)\n",
        "\n",
        "# Predicting and evaluating the model\n",
        "y_pred = collision_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Collision Risk Assessment Model Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YND5ZNap2g5",
        "outputId": "329e11eb-aed7-4c7c-c91f-bd95d4c6b30f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collision Risk Assessment Model Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Deployment"
      ],
      "metadata": {
        "id": "Fh1GxuT_p5jG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Converting the LSTM model to TensorFlow Lite\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(speed_model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the model to a .tflite file\n",
        "with open('speed_model.tflite', 'wb') as f:\n",
        "    f.write(tflite_model)\n",
        "\n",
        "print(\"Model converted to TensorFlow Lite format\")"
      ],
      "metadata": {
        "id": "etx9NFclq8wA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "WE NEED TO HAVE A ADIMAX MICROCONTROLLER FOR DEPLOYMENT"
      ],
      "metadata": {
        "id": "ET7pVb3GqL7X"
      }
    }
  ]
}